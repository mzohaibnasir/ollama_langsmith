#Langsmith for monitoring

## langchain community

all third-party integrations will be available in langchain-community

## ollama - to run llms locally

- first do `ollama run <model name>` E pulling model
  -from langchain_community.llms import ( Ollama) ; llm = Ollama(model="llama2")
