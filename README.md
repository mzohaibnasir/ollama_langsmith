#Langsmith for monitoring

## langchain community

all third-party integrations will be available in langchain-community

## ollama - to run llms locally

1. do `ollama run <model name>` E pulling model
2. from langchain_community.llms import ( Ollama) ; llm = Ollama(model="llama2")
